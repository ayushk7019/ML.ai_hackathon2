{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6395d5-da79-4d1e-980a-b71233b417ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fold 1/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8867\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's rmse: 0.88946\n",
      "LightGBM RMSE: 0.8895\n",
      "Ensemble RMSE: 0.8856\n",
      "\n",
      "==================================================\n",
      "Fold 2/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8877\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[995]\tvalid_0's rmse: 0.892339\n",
      "LightGBM RMSE: 0.8923\n",
      "Ensemble RMSE: 0.8883\n",
      "\n",
      "==================================================\n",
      "Fold 3/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8909\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[996]\tvalid_0's rmse: 0.89487\n",
      "LightGBM RMSE: 0.8949\n",
      "Ensemble RMSE: 0.8907\n",
      "\n",
      "==================================================\n",
      "Fold 4/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8946\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.90163\n",
      "LightGBM RMSE: 0.9016\n",
      "Ensemble RMSE: 0.8963\n",
      "\n",
      "==================================================\n",
      "Fold 5/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8973\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.900567\n",
      "LightGBM RMSE: 0.9006\n",
      "Ensemble RMSE: 0.8966\n",
      "\n",
      "==================================================\n",
      "Fold 6/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8922\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.896127\n",
      "LightGBM RMSE: 0.8961\n",
      "Ensemble RMSE: 0.8919\n",
      "\n",
      "==================================================\n",
      "Fold 7/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8859\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.890263\n",
      "LightGBM RMSE: 0.8903\n",
      "Ensemble RMSE: 0.8857\n",
      "\n",
      "==================================================\n",
      "OVERALL CROSS-VALIDATION SCORES\n",
      "==================================================\n",
      "XGBoost CV RMSE: 0.8908\n",
      "LightGBM CV RMSE: 0.8950\n",
      "Ensemble CV RMSE: 0.8907\n",
      "\n",
      "==================================================\n",
      "Predictions saved to 'IITG_Roll_number_Name2.csv'\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ====================\n",
    "# Load Data\n",
    "# ====================\n",
    "train_df = pd.read_csv(\"train (1).csv\")\n",
    "test_df = pd.read_csv(\"test (1).csv\")\n",
    "item_df = pd.read_csv(\"item_.csv\")\n",
    "user_df = pd.read_csv(\"user.csv\")\n",
    "genre_df = pd.read_csv(\"genre.csv\")\n",
    "\n",
    "# ====================\n",
    "# Occupation Mapping\n",
    "# ====================\n",
    "with open(\"occupation.txt\") as f:\n",
    "    occupation_list = [line.strip() for line in f]\n",
    "\n",
    "if pd.api.types.is_numeric_dtype(user_df['occupation']):\n",
    "    user_df['occupation'] = user_df['occupation'].map(\n",
    "        lambda x: occupation_list[int(x)] if pd.notnull(x) else 'unknown'\n",
    "    )\n",
    "else:\n",
    "    user_df['occupation'] = user_df['occupation'].fillna('unknown')\n",
    "\n",
    "# ====================\n",
    "# Data Preparation\n",
    "# ====================\n",
    "item_df.columns = item_df.columns.str.strip()\n",
    "item_df.rename(columns={'movie_id': 'item_id'}, inplace=True)\n",
    "\n",
    "# Merge\n",
    "train_df = train_df.merge(user_df[['user_id','age','gender','occupation']], on='user_id', how='left')\n",
    "test_df = test_df.merge(user_df[['user_id','age','gender','occupation']], on='user_id', how='left')\n",
    "train_df = train_df.merge(item_df, on='item_id', how='left')\n",
    "test_df = test_df.merge(item_df, on='item_id', how='left')\n",
    "\n",
    "# ====================\n",
    "# Advanced Feature Engineering\n",
    "# ====================\n",
    "\n",
    "def extract_year(x):\n",
    "    try:\n",
    "        return int(str(x).split(\"-\")[-1])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "train_df['release_year'] = train_df['release_date'].apply(extract_year)\n",
    "test_df['release_year'] = test_df['release_date'].apply(extract_year)\n",
    "\n",
    "# Fill missing years with median\n",
    "median_year = train_df['release_year'].median()\n",
    "train_df['release_year'].fillna(median_year, inplace=True)\n",
    "test_df['release_year'].fillna(median_year, inplace=True)\n",
    "\n",
    "# Movie age at time of rating\n",
    "train_df['movie_age'] = 1998 - train_df['release_year']  # Assuming data is from ~1998\n",
    "test_df['movie_age'] = 1998 - test_df['release_year']\n",
    "\n",
    "# Timestamp features\n",
    "train_df['rating_year'] = pd.to_datetime(train_df['timestamp'], unit='s').dt.year\n",
    "train_df['rating_month'] = pd.to_datetime(train_df['timestamp'], unit='s').dt.month\n",
    "train_df['rating_dayofweek'] = pd.to_datetime(train_df['timestamp'], unit='s').dt.dayofweek\n",
    "train_df['rating_hour'] = pd.to_datetime(train_df['timestamp'], unit='s').dt.hour\n",
    "\n",
    "# For test set, use median values\n",
    "for col in ['rating_year', 'rating_month', 'rating_dayofweek', 'rating_hour']:\n",
    "    test_df[col] = train_df[col].median()\n",
    "\n",
    "# User statistics\n",
    "user_stats = train_df.groupby('user_id').agg({\n",
    "    'rating': ['mean', 'std', 'count', 'median'],\n",
    "    'timestamp': ['min', 'max']\n",
    "}).reset_index()\n",
    "user_stats.columns = ['user_id', 'user_avg_rating', 'user_std_rating', \n",
    "                      'user_rating_count', 'user_median_rating',\n",
    "                      'user_first_rating', 'user_last_rating']\n",
    "user_stats['user_rating_span'] = user_stats['user_last_rating'] - user_stats['user_first_rating']\n",
    "user_stats['user_std_rating'].fillna(0, inplace=True)\n",
    "\n",
    "train_df = train_df.merge(user_stats, on='user_id', how='left')\n",
    "test_df = test_df.merge(user_stats, on='user_id', how='left')\n",
    "\n",
    "# Movie statistics\n",
    "movie_stats = train_df.groupby('item_id').agg({\n",
    "    'rating': ['mean', 'std', 'count', 'median'],\n",
    "}).reset_index()\n",
    "movie_stats.columns = ['item_id', 'movie_avg_rating', 'movie_std_rating', \n",
    "                       'movie_rating_count', 'movie_median_rating']\n",
    "movie_stats['movie_std_rating'].fillna(0, inplace=True)\n",
    "\n",
    "train_df = train_df.merge(movie_stats, on='item_id', how='left')\n",
    "test_df = test_df.merge(movie_stats, on='item_id', how='left')\n",
    "\n",
    "# User-Genre interaction\n",
    "genre_columns = [c for c in item_df.columns if 'genre' in c.lower()]\n",
    "if genre_columns:\n",
    "    for genre_col in genre_columns:\n",
    "        # User preference for each genre\n",
    "        genre_user_stats = train_df[train_df[genre_col] == 1].groupby('user_id')['rating'].agg(['mean', 'count']).reset_index()\n",
    "        genre_user_stats.columns = ['user_id', f'user_{genre_col}avg', f'user{genre_col}_count']\n",
    "        train_df = train_df.merge(genre_user_stats, on='user_id', how='left')\n",
    "        test_df = test_df.merge(genre_user_stats, on='user_id', how='left')\n",
    "\n",
    "# Gender-Occupation interaction\n",
    "train_df['gender_occupation'] = train_df['gender'].astype(str) + '_' + train_df['occupation'].astype(str)\n",
    "test_df['gender_occupation'] = test_df['gender'].astype(str) + '_' + test_df['occupation'].astype(str)\n",
    "\n",
    "# Age bins - convert to string to avoid categorical issues\n",
    "train_df['age_bin'] = pd.cut(train_df['age'], bins=[0,18,25,35,50,100],\n",
    "                             labels=['0','1','2','3','4']).astype(str)\n",
    "test_df['age_bin'] = pd.cut(test_df['age'], bins=[0,18,25,35,50,100],\n",
    "                            labels=['0','1','2','3','4']).astype(str)\n",
    "\n",
    "# User deviation from average\n",
    "train_df['user_deviation'] = train_df['user_avg_rating'] - train_df['rating'].mean()\n",
    "test_df['user_deviation'] = test_df['user_avg_rating'] - train_df['rating'].mean()\n",
    "\n",
    "# Movie deviation from average\n",
    "train_df['movie_deviation'] = train_df['movie_avg_rating'] - train_df['rating'].mean()\n",
    "test_df['movie_deviation'] = test_df['movie_avg_rating'] - train_df['rating'].mean()\n",
    "\n",
    "# ====================\n",
    "# Target Encoding with K-Fold\n",
    "# ====================\n",
    "def target_encode_kfold(train, test, col, target, n_splits=5):\n",
    "    \"\"\"Target encoding with K-Fold to prevent overfitting\"\"\"\n",
    "    train_encoded = np.zeros(len(train))\n",
    "    test_encoded = np.zeros(len(test))\n",
    "    \n",
    "    # Global mean for unseen categories\n",
    "    global_mean = train[target].mean()\n",
    "    \n",
    "    # K-Fold encoding for train\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for tr_idx, val_idx in kf.split(train, train[target].astype(int)):\n",
    "        target_mean = train.iloc[tr_idx].groupby(col)[target].mean()\n",
    "        train_encoded[val_idx] = train.iloc[val_idx][col].map(target_mean)\n",
    "    \n",
    "    # Fill NaN with global mean\n",
    "    train_encoded = np.where(np.isnan(train_encoded), global_mean, train_encoded)\n",
    "    \n",
    "    # Encode test using all training data\n",
    "    target_mean = train.groupby(col)[target].mean()\n",
    "    test_encoded = test[col].map(target_mean).fillna(global_mean)\n",
    "    \n",
    "    return train_encoded, test_encoded\n",
    "\n",
    "# Apply target encoding\n",
    "train_df['occupation_encoded'], test_df['occupation_encoded'] = target_encode_kfold(\n",
    "    train_df, test_df, 'occupation', 'rating')\n",
    "\n",
    "train_df['gender_occ_encoded'], test_df['gender_occ_encoded'] = target_encode_kfold(\n",
    "    train_df, test_df, 'gender_occupation', 'rating')\n",
    "\n",
    "# ====================\n",
    "# Label Encoding for categorical features\n",
    "# ====================\n",
    "for col in ['gender', 'occupation', 'age_bin']:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    test_df[col] = test_df[col].map(lambda x: le.transform([str(x)])[0] if str(x) in le.classes_ else -1)\n",
    "\n",
    "# ====================\n",
    "# Fill missing values BEFORE label encoding for genre columns\n",
    "# ====================\n",
    "# Identify all columns in the dataframe\n",
    "all_cols = train_df.columns.tolist()\n",
    "\n",
    "# Fill missing values for numeric columns only\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if train_df[col].isnull().any():\n",
    "        train_df[col].fillna(-999, inplace=True)\n",
    "    if col in test_df.columns and test_df[col].isnull().any():\n",
    "        test_df[col].fillna(-999, inplace=True)\n",
    "\n",
    "# ====================\n",
    "# Feature Selection\n",
    "# ====================\n",
    "drop_cols = ['rating', 'timestamp', 'title', 'release_date', 'imdb_url', \n",
    "             'user_first_rating', 'user_last_rating', 'gender_occupation']\n",
    "feature_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "\n",
    "test_drop_cols = ['id', 'title', 'release_date', 'imdb_url', \n",
    "                  'user_first_rating', 'user_last_rating', 'gender_occupation']\n",
    "test_feature_cols = [c for c in test_df.columns if c not in test_drop_cols]\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['rating']\n",
    "X_test = test_df[test_feature_cols]\n",
    "\n",
    "# ====================\n",
    "# Stratified K-Fold Cross Validation\n",
    "# ====================\n",
    "n_splits = 7\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds_xgb = np.zeros(len(X))\n",
    "oof_preds_lgb = np.zeros(len(X))\n",
    "test_preds_xgb = np.zeros(len(X_test))\n",
    "test_preds_lgb = np.zeros(len(X_test))\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in skf.split(X, y.astype(int)):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold}/{n_splits}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # ========== XGBoost ==========\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    \n",
    "    xgb_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'max_depth': 7,\n",
    "        'learning_rate': 0.03,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 3,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 2,\n",
    "        'gamma': 0.1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    xgb_model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        early_stopping_rounds=50,\n",
    "        evals=[(dval, 'eval')],\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    val_preds_xgb = xgb_model.predict(dval)\n",
    "    oof_preds_xgb[val_idx] = val_preds_xgb\n",
    "    test_preds_xgb += xgb_model.predict(dtest) / n_splits\n",
    "    \n",
    "    rmse_xgb = mean_squared_error(y_val, val_preds_xgb, squared=False)\n",
    "    print(f\"XGBoost RMSE: {rmse_xgb:.4f}\")\n",
    "    \n",
    "    # ========== LightGBM ==========\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.03,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'min_child_samples': 20,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 2,\n",
    "        'verbose': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.train(\n",
    "        lgb_params,\n",
    "        lgb_train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[lgb_val],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    val_preds_lgb = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
    "    oof_preds_lgb[val_idx] = val_preds_lgb\n",
    "    test_preds_lgb += lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration) / n_splits\n",
    "    \n",
    "    rmse_lgb = mean_squared_error(y_val, val_preds_lgb, squared=False)\n",
    "    print(f\"LightGBM RMSE: {rmse_lgb:.4f}\")\n",
    "    \n",
    "    # Ensemble predictions\n",
    "    val_preds_ensemble = 0.5 * val_preds_xgb + 0.5 * val_preds_lgb\n",
    "    rmse_ensemble = mean_squared_error(y_val, val_preds_ensemble, squared=False)\n",
    "    print(f\"Ensemble RMSE: {rmse_ensemble:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# ====================\n",
    "# Overall CV Scores\n",
    "# ====================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"OVERALL CROSS-VALIDATION SCORES\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "cv_rmse_xgb = mean_squared_error(y, oof_preds_xgb, squared=False)\n",
    "print(f\"XGBoost CV RMSE: {cv_rmse_xgb:.4f}\")\n",
    "\n",
    "cv_rmse_lgb = mean_squared_error(y, oof_preds_lgb, squared=False)\n",
    "print(f\"LightGBM CV RMSE: {cv_rmse_lgb:.4f}\")\n",
    "\n",
    "oof_preds_ensemble = 0.5 * oof_preds_xgb + 0.5 * oof_preds_lgb\n",
    "cv_rmse_ensemble = mean_squared_error(y, oof_preds_ensemble, squared=False)\n",
    "print(f\"Ensemble CV RMSE: {cv_rmse_ensemble:.4f}\")\n",
    "\n",
    "# ====================\n",
    "# Final Predictions\n",
    "# ====================\n",
    "# Ensemble predictions\n",
    "test_preds_ensemble = 0.5 * test_preds_xgb + 0.5 * test_preds_lgb\n",
    "\n",
    "# Clip and round\n",
    "y_test_pred_clipped = np.clip(np.round(test_preds_ensemble), 1, 5)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'rating': y_test_pred_clipped.astype(int)\n",
    "})\n",
    "submission.to_csv('IITG_Roll_number_Name2.csv', index=False)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Predictions saved to 'IITG_Roll_number_Name2.csv'\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c3777-587e-4973-af6a-fdcf41dfafac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IITG.AI]",
   "language": "python",
   "name": "conda-env-IITG.AI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
