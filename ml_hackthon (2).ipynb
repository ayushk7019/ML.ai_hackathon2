{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d36c3777-587e-4973-af6a-fdcf41dfafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings to avoid unnecessary clutter\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c18d6173-0717-4aa2-a920-6ede807934f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Load Data\n",
    "# ====================\n",
    "# Load the datasets for training, testing, item data, user data, and genre data\n",
    "train_df = pd.read_csv(\"train (1).csv\")\n",
    "test_df = pd.read_csv(\"test (1).csv\")\n",
    "item_df = pd.read_csv(\"item_.csv\")\n",
    "user_df = pd.read_csv(\"user.csv\")\n",
    "genre_df = pd.read_csv(\"genre.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11b7a1e8-6ac9-4bc3-9764-6e6ba9f992ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Occupation Mapping\n",
    "# ====================\n",
    "# Load the occupation list from a text file\n",
    "with open(\"occupation.txt\") as f:\n",
    "    occupation_list = [line.strip() for line in f]\n",
    "\n",
    "# If the 'occupation' column is numeric, map it to the occupation list\n",
    "if pd.api.types.is_numeric_dtype(user_df['occupation']):\n",
    "    user_df['occupation'] = user_df['occupation'].map(\n",
    "        lambda x: occupation_list[int(x)] if pd.notnull(x) else 'unknown'\n",
    "    )\n",
    "else:\n",
    "    user_df['occupation'] = user_df['occupation'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afaba1ef-10af-4b91-ae63-edd4b57f5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Data Preparation\n",
    "# ====================\n",
    "# Clean column names in the item dataframe by stripping leading/trailing spaces\n",
    "item_df.columns = item_df.columns.str.strip()\n",
    "\n",
    "# Rename 'movie_id' column to 'item_id' for consistency across dataframes\n",
    "item_df.rename(columns={'movie_id': 'item_id'}, inplace=True)\n",
    "\n",
    "# Merge the user data into the training and testing datasets\n",
    "train_df = train_df.merge(user_df[['user_id','age','gender','occupation']], on='user_id', how='left')\n",
    "test_df = test_df.merge(user_df[['user_id','age','gender','occupation']], on='user_id', how='left')\n",
    "\n",
    "# Merge the item data into the training and testing datasets\n",
    "train_df = train_df.merge(item_df, on='item_id', how='left')\n",
    "test_df = test_df.merge(item_df, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41bd1a3f-26b6-4c34-9fcc-da178f34d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Advanced Feature Engineering\n",
    "# ====================\n",
    "\n",
    "# Function to extract the release year from the release date\n",
    "def extract_year(x):\n",
    "    try:\n",
    "        return int(str(x).split(\"-\")[-1])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the extract_year function to get the release year for each movie\n",
    "train_df['release_year'] = train_df['release_date'].apply(extract_year)\n",
    "test_df['release_year'] = test_df['release_date'].apply(extract_year)\n",
    "\n",
    "# Fill missing values for release year with the median value of the training set\n",
    "median_year = train_df['release_year'].median()\n",
    "train_df['release_year'].fillna(median_year, inplace=True)\n",
    "test_df['release_year'].fillna(median_year, inplace=True)\n",
    "\n",
    "# Calculate movie age at the time of rating (assuming data is from 1998)\n",
    "train_df['movie_age'] = 1998 - train_df['release_year']\n",
    "test_df['movie_age'] = 1998 - test_df['release_year']\n",
    "\n",
    "# Generate features based on the timestamp (year, month, day of week, hour)\n",
    "train_df['rating_year'] = pd.to_datetime(train_df['timestamp'], unit='s').dt.year\n",
    "train_df['rating_month'] = pd.to_datetime(train_df['timestamp'], unit='s').dt.month\n",
    "train_df['rating_dayofweek'] = pd.to_datetime(train_df['timestamp'], unit='s').dt.dayofweek\n",
    "train_df['rating_hour'] = pd.to_datetime(train_df['timestamp'], unit='s').dt.hour\n",
    "\n",
    "# For the test set, use the median values of these features from the training set\n",
    "for col in ['rating_year', 'rating_month', 'rating_dayofweek', 'rating_hour']:\n",
    "    test_df[col] = train_df[col].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed59db03-ce77-4148-8916-5bf45501ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# User Statistics\n",
    "# ====================\n",
    "# Calculate user-specific statistics: average rating, standard deviation, rating count, etc.\n",
    "user_stats = train_df.groupby('user_id').agg({\n",
    "    'rating': ['mean', 'std', 'count', 'median'],\n",
    "    'timestamp': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns in the user statistics dataframe\n",
    "user_stats.columns = ['user_id', 'user_avg_rating', 'user_std_rating', \n",
    "                      'user_rating_count', 'user_median_rating',\n",
    "                      'user_first_rating', 'user_last_rating']\n",
    "\n",
    "# Calculate the time span between first and last ratings for each user\n",
    "user_stats['user_rating_span'] = user_stats['user_last_rating'] - user_stats['user_first_rating']\n",
    "\n",
    "# Fill missing values for standard deviation with 0\n",
    "user_stats['user_std_rating'].fillna(0, inplace=True)\n",
    "\n",
    "# Merge user statistics into the training and testing datasets\n",
    "train_df = train_df.merge(user_stats, on='user_id', how='left')\n",
    "test_df = test_df.merge(user_stats, on='user_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7545bd9-8a09-423b-a096-48e5cd08dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Movie Statistics\n",
    "# ====================\n",
    "# Calculate movie-specific statistics: average rating, standard deviation, rating count, etc.\n",
    "movie_stats = train_df.groupby('item_id').agg({\n",
    "    'rating': ['mean', 'std', 'count', 'median'],\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns in the movie statistics dataframe\n",
    "movie_stats.columns = ['item_id', 'movie_avg_rating', 'movie_std_rating', \n",
    "                       'movie_rating_count', 'movie_median_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60bec53d-08fd-467c-88af-46e1dee14c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for standard deviation with 0\n",
    "movie_stats['movie_std_rating'].fillna(0, inplace=True)\n",
    "\n",
    "# Merge movie statistics into the training and testing datasets\n",
    "train_df = train_df.merge(movie_stats, on='item_id', how='left')\n",
    "test_df = test_df.merge(movie_stats, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a773a4c1-7aef-482d-9d07-034245106b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# User-Genre Interaction\n",
    "# ====================\n",
    "# If there are genre columns, calculate user preference for each genre\n",
    "genre_columns = [c for c in item_df.columns if 'genre' in c.lower()]\n",
    "if genre_columns:\n",
    "    for genre_col in genre_columns:\n",
    "        # Calculate user preference for each genre based on ratings\n",
    "        genre_user_stats = train_df[train_df[genre_col] == 1].groupby('user_id')['rating'].agg(['mean', 'count']).reset_index()\n",
    "        genre_user_stats.columns = ['user_id', f'user_{genre_col}avg', f'user{genre_col}_count']\n",
    "        train_df = train_df.merge(genre_user_stats, on='user_id', how='left')\n",
    "        test_df = test_df.merge(genre_user_stats, on='user_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53394216-5cc6-4e32-8441-3796e2073720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Gender-Occupation Interaction\n",
    "# ====================\n",
    "# Combine gender and occupation into a single feature for interaction modeling\n",
    "train_df['gender_occupation'] = train_df['gender'].astype(str) + '_' + train_df['occupation'].astype(str)\n",
    "test_df['gender_occupation'] = test_df['gender'].astype(str) + '_' + test_df['occupation'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be824ae2-7319-4b73-8b7f-c5840446fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Age Bins\n",
    "# ====================\n",
    "# Create age bins to categorize users into different age groups\n",
    "train_df['age_bin'] = pd.cut(train_df['age'], bins=[0,18,25,35,50,100],\n",
    "                             labels=['0','1','2','3','4']).astype(str)\n",
    "test_df['age_bin'] = pd.cut(test_df['age'], bins=[0,18,25,35,50,100],\n",
    "                            labels=['0','1','2','3','4']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b158c06-bb1d-4fc3-bbd1-b6a179ea5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# User and Movie Deviation from Average Rating\n",
    "# ====================\n",
    "# Calculate how far a user's rating deviates from the overall average\n",
    "train_df['user_deviation'] = train_df['user_avg_rating'] - train_df['rating'].mean()\n",
    "test_df['user_deviation'] = test_df['user_avg_rating'] - train_df['rating'].mean()\n",
    "\n",
    "# Calculate how far a movie's rating deviates from the overall average\n",
    "train_df['movie_deviation'] = train_df['movie_avg_rating'] - train_df['rating'].mean()\n",
    "test_df['movie_deviation'] = test_df['movie_avg_rating'] - train_df['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5278b15e-7231-43d4-a65a-b8df86b35fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Target Encoding with K-Fold\n",
    "# ====================\n",
    "# Function for target encoding using K-Fold cross-validation to prevent overfitting\n",
    "def target_encode_kfold(train, test, col, target, n_splits=5):\n",
    "    train_encoded = np.zeros(len(train))\n",
    "    test_encoded = np.zeros(len(test))\n",
    "    \n",
    "    # Global mean for unseen categories\n",
    "    global_mean = train[target].mean()\n",
    "    \n",
    "    # K-Fold encoding for train\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for tr_idx, val_idx in kf.split(train, train[target].astype(int)):\n",
    "        target_mean = train.iloc[tr_idx].groupby(col)[target].mean()\n",
    "        train_encoded[val_idx] = train.iloc[val_idx][col].map(target_mean)\n",
    "    \n",
    "    # Fill NaN with global mean\n",
    "    train_encoded = np.where(np.isnan(train_encoded), global_mean, train_encoded)\n",
    "    \n",
    "    # Encode test using all training data\n",
    "    target_mean = train.groupby(col)[target].mean()\n",
    "    test_encoded = test[col].map(target_mean).fillna(global_mean)\n",
    "    \n",
    "    return train_encoded, test_encoded\n",
    "\n",
    "# Apply target encoding to 'occupation' and 'gender_occupation'\n",
    "train_df['occupation_encoded'], test_df['occupation_encoded'] = target_encode_kfold(\n",
    "    train_df, test_df, 'occupation', 'rating')\n",
    "\n",
    "train_df['gender_occ_encoded'], test_df['gender_occ_encoded'] = target_encode_kfold(\n",
    "    train_df, test_df, 'gender_occupation', 'rating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a3e0549-cc2c-447d-8fd1-d955dd5ad9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Label Encoding for Categorical Features\n",
    "# ====================\n",
    "# Convert categorical columns like gender, occupation, and age_bin into numerical values\n",
    "for col in ['gender', 'occupation', 'age_bin']:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col].astype(str))\n",
    "    test_df[col] = test_df[col].map(lambda x: le.transform([str(x)])[0] if str(x) in le.classes_ else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99441ee4-17d6-4af8-b2a5-52b94f0da596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Fill Missing Values BEFORE Label Encoding for Genre Columns\n",
    "# ====================\n",
    "# Identify numeric columns and fill any missing values with -999\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if train_df[col].isnull().any():\n",
    "        train_df[col].fillna(-999, inplace=True)\n",
    "    if col in test_df.columns and test_df[col].isnull().any():\n",
    "        test_df[col].fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40911ba8-806d-4028-8aba-d888b97ebb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Feature Selection\n",
    "# ====================\n",
    "# Drop irrelevant columns and select the remaining features for the model\n",
    "drop_cols = ['rating', 'timestamp', 'title', 'release_date', 'imdb_url', \n",
    "             'user_first_rating', 'user_last_rating', 'gender_occupation']\n",
    "feature_cols = [c for c in train_df.columns if c not in drop_cols]\n",
    "\n",
    "test_drop_cols = ['id', 'title', 'release_date', 'imdb_url', \n",
    "                  'user_first_rating', 'user_last_rating', 'gender_occupation']\n",
    "test_feature_cols = [c for c in test_df.columns if c not in test_drop_cols]\n",
    "\n",
    "# Prepare the feature matrix and target vector\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['rating']\n",
    "X_test = test_df[test_feature_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e70c6cb-ddcf-4fb0-999f-40ff8c97a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Fold 1/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8867\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's rmse: 0.88946\n",
      "LightGBM RMSE: 0.8895\n",
      "Ensemble RMSE: 0.8856\n",
      "\n",
      "==================================================\n",
      "Fold 2/7\n",
      "==================================================\n",
      "XGBoost RMSE: 0.8877\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    }
   ],
   "source": [
    "# ====================\n",
    "# Stratified K-Fold Cross Validation\n",
    "# ====================\n",
    "n_splits = 7\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "oof_preds_xgb = np.zeros(len(X))\n",
    "oof_preds_lgb = np.zeros(len(X))\n",
    "test_preds_xgb = np.zeros(len(X_test))\n",
    "test_preds_lgb = np.zeros(len(X_test))\n",
    "\n",
    "# Cross-validation loop for both models (XGBoost and LightGBM)\n",
    "fold = 1\n",
    "for train_idx, val_idx in skf.split(X, y.astype(int)):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold}/{n_splits}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # ========== XGBoost ==========\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    \n",
    "    xgb_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'max_depth': 7,\n",
    "        'learning_rate': 0.03,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 3,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 2,\n",
    "        'gamma': 0.1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    xgb_model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        early_stopping_rounds=50,\n",
    "        evals=[(dval, 'eval')],\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    val_preds_xgb = xgb_model.predict(dval)\n",
    "    oof_preds_xgb[val_idx] = val_preds_xgb\n",
    "    test_preds_xgb += xgb_model.predict(dtest) / n_splits\n",
    "    \n",
    "    rmse_xgb = mean_squared_error(y_val, val_preds_xgb, squared=False)\n",
    "    print(f\"XGBoost RMSE: {rmse_xgb:.4f}\")\n",
    "    \n",
    "    # ========== LightGBM ==========\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    \n",
    "    lgb_params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.03,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'min_child_samples': 20,\n",
    "        'reg_alpha': 0.5,\n",
    "        'reg_lambda': 2,\n",
    "        'verbose': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.train(\n",
    "        lgb_params,\n",
    "        lgb_train,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[lgb_val],\n",
    "        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "    )\n",
    "    \n",
    "    val_preds_lgb = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
    "    oof_preds_lgb[val_idx] = val_preds_lgb\n",
    "    test_preds_lgb += lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration) / n_splits\n",
    "    \n",
    "    rmse_lgb = mean_squared_error(y_val, val_preds_lgb, squared=False)\n",
    "    print(f\"LightGBM RMSE: {rmse_lgb:.4f}\")\n",
    "    \n",
    "    # Ensemble predictions\n",
    "    val_preds_ensemble = 0.5 * val_preds_xgb + 0.5 * val_preds_lgb\n",
    "    rmse_ensemble = mean_squared_error(y_val, val_preds_ensemble, squared=False)\n",
    "    print(f\"Ensemble RMSE: {rmse_ensemble:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# ====================\n",
    "# Overall CV Scores\n",
    "# ====================\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"OVERALL CROSS-VALIDATION SCORES\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697b6ae-c0b3-45e8-920f-358cd88fe02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall CV RMSE for each model and ensemble\n",
    "cv_rmse_xgb = mean_squared_error(y, oof_preds_xgb, squared=False)\n",
    "print(f\"XGBoost CV RMSE: {cv_rmse_xgb:.4f}\")\n",
    "\n",
    "cv_rmse_lgb = mean_squared_error(y, oof_preds_lgb, squared=False)\n",
    "print(f\"LightGBM CV RMSE: {cv_rmse_lgb:.4f}\")\n",
    "\n",
    "oof_preds_ensemble = 0.5 * oof_preds_xgb + 0.5 * oof_preds_lgb\n",
    "cv_rmse_ensemble = mean_squared_error(y, oof_preds_ensemble, squared=False)\n",
    "print(f\"Ensemble CV RMSE: {cv_rmse_ensemble:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421b456-39f3-4e23-8144-768389bcf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Final Predictions\n",
    "# ====================\n",
    "# Generate final ensemble predictions for the test set\n",
    "test_preds_ensemble = 0.5 * test_preds_xgb + 0.5 * test_preds_lgb\n",
    "\n",
    "# Clip predictions to ensure they fall within the valid range (1 to 5)\n",
    "y_test_pred_clipped = np.clip(np.round(test_preds_ensemble), 1, 5)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'timestamp': test_df['id'],\n",
    "    'rating': y_test_pred_clipped.astype(int)\n",
    "})\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "submission.to_csv('IITG_240107019_Ayush_kumar3.csv', index=False)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Predictions saved to 'IITG_240107019_Ayush_kumar3.csv'\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324a510-c1fd-4e95-8fcf-8225e3aabe3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IITG.AI]",
   "language": "python",
   "name": "conda-env-IITG.AI-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
